<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SmolVLM 交互demo</title>
    <style>
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            padding: 20px;
            background-color: #f0f0f0;
        }
        .controls, .io-areas {
            display: flex;
            gap: 10px;
            align-items: center;
            background-color: #fff;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .io-areas {
            flex-direction: column;
            align-items: stretch;
        }
        textarea {
            width: 300px;
            height: 80px;
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 14px;
        }
        #videoFeed {
            width: 480px;
            height: 360px;
            border: 2px solid #333;
            background-color: #000;
            border-radius: 8px;
        }
        #faceDetectionCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 480px;
            height: 360px;
            pointer-events: none; /* 允许点击穿透到下面的视频元素 */
        }
        #cameraContainer {
            position: relative; /* 为了让canvas能够绝对定位在视频上方 */
        }
        #startButton {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 4px;
            color: white;
        }
        #startButton.start {
            background-color: #28a745; /* Green */
        }
        #startButton.stop {
            background-color: #dc3545; /* Red */
        }
        label {
            font-weight: bold;
        }
        select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ccc;
        }
        .hidden {
            display: none;
        }
        .mode-selector {
            margin-bottom: 15px;
            background-color: #fff;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }
        .mode-buttons {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 8px;
        }
        .mode-button {
            padding: 8px 16px;
            border: 1px solid #ccc;
            border-radius: 4px;
            background-color: #f0f0f0;
            cursor: pointer;
            font-size: 14px;
        }
        .mode-button.active {
            background-color: #007bff;
            color: white;
            border-color: #0056b3;
        }
        #imageContainer {
            width: 480px;
            margin-bottom: 15px;
        }
        .image-input-area {
            background-color: #fff;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin-bottom: 10px;
        }
        .local-image, .url-image {
            margin-bottom: 10px;
        }
        #imageUpload {
            margin-top: 5px;
        }
        #imageUrl {
            width: 70%;
            padding: 6px;
            margin-top: 5px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        #loadUrlImage {
            padding: 6px 12px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        #selectedImage {
            max-width: 480px;
            max-height: 360px;
            border: 2px solid #333;
            border-radius: 8px;
            background-color: #f0f0f0;
        }
    </style>
</head>
<body>

    <h1>SmolVLM 交互demo</h1>

    <div class="mode-selector">
        <label>模式选择:</label>
        <div class="mode-buttons">
            <button id="cameraMode" class="mode-button active">摄像头模式</button>
            <button id="imageMode" class="mode-button">图像模式</button>
        </div>
    </div>

    <div id="cameraContainer">
        <video id="videoFeed" autoplay playsinline></video>
        <canvas id="faceDetectionCanvas" width="480" height="360"></canvas> <!-- 用于显示人脸检测结果 -->
    </div>

    <div id="imageContainer" class="hidden">
        <div class="image-input-area">
            <div class="local-image">
                <label for="imageUpload">选择本地图像:</label>
                <input type="file" id="imageUpload" accept="image/*">
            </div>
            <div class="url-image">
                <label for="imageUrl">或输入图像URL:</label>
                <input type="text" id="imageUrl" placeholder="https://example.com/image.jpg">
                <button id="loadUrlImage">加载</button>
            </div>
        </div>
        <img id="selectedImage" class="hidden" alt="选择的图像">
    </div>

    <canvas id="canvas" class="hidden"></canvas> <!-- 用于捕获帧 -->

    <div class="io-areas">
        <div>
            <label for="baseURL">基础API地址:</label><br>
            <input id="baseURL" name="Instruction" value="http://localhost:8080"></textarea>
        </div>
        <div>
            <label for="instructionText">指令:</label><br>
            <textarea id="instructionText" style="height: 2em; width: 40em" name="Instruction"></textarea>
        </div>
        <div>
            <label for="responseText">响应:</label><br>
            <textarea id="responseText" style="height: 2em; width: 40em" name="Response" readonly placeholder="服务器响应将显示在这里..."></textarea>
        </div>
    </div>

    <div class="controls">
        <label for="intervalSelect">两次请求之间的间隔:</label>
        <select id="intervalSelect" name="Interval between 2 requests">
            <option value="100">100毫秒</option>
            <option value="250">250毫秒</option>
            <option value="500" selected>500毫秒</option>
            <option value="1000">1秒</option>
            <option value="2000">2秒</option>
        </select>
        <div style="display: flex; align-items: center; margin-left: 15px;">
            <input type="checkbox" id="faceDetectionMode" name="faceDetectionMode">
            <label for="faceDetectionMode" style="margin-left: 5px;">专注人脸识别</label>
        </div>
        <button id="startButton" class="start">开始</button>
    </div>

    <script>
        const video = document.getElementById('videoFeed');
        const canvas = document.getElementById('canvas');
        const faceDetectionCanvas = document.getElementById('faceDetectionCanvas');
        const baseURL = document.getElementById('baseURL');
        const instructionText = document.getElementById('instructionText');
        const responseText = document.getElementById('responseText');
        const intervalSelect = document.getElementById('intervalSelect');
        const startButton = document.getElementById('startButton');
        const faceDetectionMode = document.getElementById('faceDetectionMode');

        // 模式切换元素
        const cameraModeBtn = document.getElementById('cameraMode');
        const imageModeBtn = document.getElementById('imageMode');
        const cameraContainer = document.getElementById('cameraContainer');
        const imageContainer = document.getElementById('imageContainer');

        // 图像模式元素
        const imageUpload = document.getElementById('imageUpload');
        const imageUrl = document.getElementById('imageUrl');
        const loadUrlImageBtn = document.getElementById('loadUrlImage');
        const selectedImage = document.getElementById('selectedImage');

        // 默认指令和专注人脸识别指令
        const defaultInstruction = "What do you see?";
        const faceDetectionInstruction = "IMPORTANT: You must ONLY detect faces in this image and return ONLY their bounding box coordinates in EXACTLY this JSON format: {\"faces\": [{\"x\": number, \"y\": number, \"width\": number, \"height\": number}]}. If no faces are detected, return {\"faces\": []}. DO NOT describe the image. DO NOT add any other text. ONLY return the JSON. NEVER make up coordinates if you don't see a face.";

        // 设置默认指令
        instructionText.value = defaultInstruction;

        let stream;
        let intervalId;
        let isProcessing = false;
        let currentMode = 'camera'; // 'camera' 或 'image'
        let detectedFaces = []; // 存储检测到的人脸坐标
        let previousFaces = []; // 存储上一次检测到的人脸坐标，用于防抖动
        let noFaceCounter = 0; // 连续未检测到人脸的次数
        const MAX_NO_FACE_COUNT = 3; // 连续多少次未检测到人脸才清除框

        // 验证人脸坐标是否合理
        function isValidFaceCoordinate(face) {
            // 检查坐标是否为数字
            if (typeof face.x !== 'number' || typeof face.y !== 'number' ||
                typeof face.width !== 'number' || typeof face.height !== 'number') {
                return false;
            }

            // 检查坐标是否在合理范围内
            if (face.x < 0 || face.y < 0 || face.width <= 0 || face.height <= 0) {
                return false;
            }

            // 检查坐标是否在画布范围内
            if (face.x + face.width > faceDetectionCanvas.width ||
                face.y + face.height > faceDetectionCanvas.height) {
                return false;
            }

            // 检查人脸框大小是否合理（太小或太大的框可能是错误的）
            const minSize = 20; // 最小20像素
            const maxSizeRatio = 0.9; // 最大不超过画布的90%

            if (face.width < minSize || face.height < minSize) {
                return false;
            }

            if (face.width > faceDetectionCanvas.width * maxSizeRatio ||
                face.height > faceDetectionCanvas.height * maxSizeRatio) {
                return false;
            }

            // 检查宽高比是否合理（人脸通常不会太扁或太长）
            const aspectRatio = face.width / face.height;
            if (aspectRatio < 0.5 || aspectRatio > 2.0) {
                return false;
            }

            return true;
        }

        // 计算两个人脸框的相似度（0-1之间，1表示完全相同）
        function calculateFaceSimilarity(face1, face2) {
            // 计算中心点距离
            const center1X = face1.x + face1.width / 2;
            const center1Y = face1.y + face1.height / 2;
            const center2X = face2.x + face2.width / 2;
            const center2Y = face2.y + face2.height / 2;

            // 计算中心点距离与画布对角线的比值（归一化）
            const canvasDiagonal = Math.sqrt(Math.pow(faceDetectionCanvas.width, 2) + Math.pow(faceDetectionCanvas.height, 2));
            const centerDistance = Math.sqrt(Math.pow(center1X - center2X, 2) + Math.pow(center1Y - center2Y, 2));
            const normalizedDistance = 1 - (centerDistance / canvasDiagonal);

            // 计算大小相似度
            const area1 = face1.width * face1.height;
            const area2 = face2.width * face2.height;
            const areaRatio = Math.min(area1, area2) / Math.max(area1, area2);

            // 综合相似度（距离和大小各占50%权重）
            return normalizedDistance * 0.7 + areaRatio * 0.3;
        }

        // 查找最相似的人脸
        function findMostSimilarFace(face, faceArray) {
            let maxSimilarity = 0;
            let mostSimilarFace = null;

            for (const candidateFace of faceArray) {
                const similarity = calculateFaceSimilarity(face, candidateFace);
                if (similarity > maxSimilarity) {
                    maxSimilarity = similarity;
                    mostSimilarFace = candidateFace;
                }
            }

            // 只有相似度大于阈值才认为是相似的人脸
            return maxSimilarity > 0.7 ? mostSimilarFace : null;
        }

        // 平滑人脸坐标，减少抖动
        function smoothFaceCoordinates(currentFaces) {
            // 如果没有当前人脸，增加无人脸计数器
            if (currentFaces.length === 0) {
                noFaceCounter++;

                // 如果连续多次没有检测到人脸，才清除之前的人脸框
                if (noFaceCounter >= MAX_NO_FACE_COUNT) {
                    previousFaces = [];
                    return [];
                } else {
                    // 否则继续使用之前的人脸框
                    return previousFaces;
                }
            }

            // 重置无人脸计数器
            noFaceCounter = 0;

            // 如果之前没有人脸，直接使用当前人脸
            if (previousFaces.length === 0) {
                previousFaces = [...currentFaces];
                return currentFaces;
            }

            // 平滑处理：将当前人脸与之前人脸进行匹配和平均
            const smoothedFaces = [];

            // 处理当前检测到的每个人脸
            for (const currentFace of currentFaces) {
                // 查找之前帧中最相似的人脸
                const similarPreviousFace = findMostSimilarFace(currentFace, previousFaces);

                if (similarPreviousFace) {
                    // 如果找到相似的人脸，进行平滑处理（加权平均）
                    const weight = 0.3; // 当前帧权重
                    const smoothedFace = {
                        x: Math.round(currentFace.x * weight + similarPreviousFace.x * (1 - weight)),
                        y: Math.round(currentFace.y * weight + similarPreviousFace.y * (1 - weight)),
                        width: Math.round(currentFace.width * weight + similarPreviousFace.width * (1 - weight)),
                        height: Math.round(currentFace.height * weight + similarPreviousFace.height * (1 - weight))
                    };
                    smoothedFaces.push(smoothedFace);
                } else {
                    // 如果没有找到相似的人脸，直接使用当前人脸
                    smoothedFaces.push(currentFace);
                }
            }

            // 更新previousFaces用于下一次比较
            previousFaces = [...smoothedFaces];

            return smoothedFaces;
        }

        // 绘制人脸检测框的函数
        function drawFaceBoxes() {
            const ctx = faceDetectionCanvas.getContext('2d');
            ctx.clearRect(0, 0, faceDetectionCanvas.width, faceDetectionCanvas.height);

            // 过滤掉不合理的人脸坐标
            const validFaces = detectedFaces.filter(isValidFaceCoordinate);

            // 应用平滑处理，减少抖动
            const smoothedFaces = smoothFaceCoordinates(validFaces);

            if (smoothedFaces.length === 0) return;

            ctx.strokeStyle = 'red';
            ctx.lineWidth = 3;

            smoothedFaces.forEach(face => {
                ctx.strokeRect(face.x, face.y, face.width, face.height);
            });
        }

        // 解析SmolVLM返回的JSON响应
        function parseFaceDetectionResponse(response) {
            try {
                // 清除之前的人脸框
                detectedFaces = [];

                // 检查响应是否明确表示没有人脸
                if (response.toLowerCase().includes("no face") ||
                    response.toLowerCase().includes("no faces") ||
                    response.toLowerCase().includes("cannot detect") ||
                    response.toLowerCase().includes("didn't detect") ||
                    response.toLowerCase().includes("not detect") ||
                    response.toLowerCase().includes("no person")) {
                    console.log("响应明确表示没有检测到人脸");
                    drawFaceBoxes();
                    return;
                }

                // 检查是否有空的faces数组，表示没有检测到人脸
                if (response.includes('"faces":[]') || response.includes('"faces": []')) {
                    console.log("检测到空的faces数组，表示没有人脸");
                    drawFaceBoxes();
                    return;
                }

                // 尝试直接解析完整JSON
                let jsonMatch = response.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    try {
                        const jsonStr = jsonMatch[0];
                        const data = JSON.parse(jsonStr);

                        if (data && data.faces && Array.isArray(data.faces)) {
                            // 标准格式：{"faces": [{x, y, width, height}, ...]}
                            if (data.faces.length === 0) {
                                console.log("JSON中faces数组为空，表示没有人脸");
                                drawFaceBoxes();
                                return;
                            }

                            // 过滤出有效的人脸坐标
                            const validFaces = data.faces.filter(face =>
                                typeof face.x === 'number' &&
                                typeof face.y === 'number' &&
                                typeof face.width === 'number' &&
                                typeof face.height === 'number'
                            );

                            if (validFaces.length > 0) {
                                detectedFaces = validFaces;
                                console.log(`成功解析到${validFaces.length}个人脸坐标`);
                                drawFaceBoxes();
                                return;
                            } else {
                                console.log("JSON中faces数组不包含有效的人脸坐标");
                            }
                        }
                    } catch (e) {
                        console.log('完整JSON解析失败，尝试其他方法:', e.message);
                    }
                }

                // 如果是专注人脸识别模式但没有找到标准JSON，可能是模型没有按照要求输出
                if (faceDetectionMode.checked) {
                    console.log("专注人脸识别模式下未找到标准JSON格式，尝试其他解析方法");
                }

                // 尝试从文本中提取单个人脸坐标对象
                const faceObjRegex = /\{\s*"x"\s*:\s*(\d+)\s*,\s*"y"\s*:\s*(\d+)\s*,\s*"width"\s*:\s*(\d+)\s*,\s*"height"\s*:\s*(\d+)\s*\}/g;
                let match;
                let extractedFaces = [];

                while ((match = faceObjRegex.exec(response)) !== null) {
                    extractedFaces.push({
                        x: parseInt(match[1]),
                        y: parseInt(match[2]),
                        width: parseInt(match[3]),
                        height: parseInt(match[4])
                    });
                }

                if (extractedFaces.length > 0) {
                    console.log(`从文本中提取到${extractedFaces.length}个人脸坐标对象`);
                    detectedFaces = extractedFaces;
                    drawFaceBoxes();
                    return;
                }

                // 如果上面的方法都失败，尝试提取数字坐标
                // 查找形如 "x: 100, y: 200, width: 150, height: 150" 的模式
                const coordRegex = /x\s*[:=]\s*(\d+)[,\s]+y\s*[:=]\s*(\d+)[,\s]+width\s*[:=]\s*(\d+)[,\s]+height\s*[:=]\s*(\d+)/gi;
                extractedFaces = [];

                while ((match = coordRegex.exec(response)) !== null) {
                    extractedFaces.push({
                        x: parseInt(match[1]),
                        y: parseInt(match[2]),
                        width: parseInt(match[3]),
                        height: parseInt(match[4])
                    });
                }

                if (extractedFaces.length > 0) {
                    console.log(`从文本描述中提取到${extractedFaces.length}个人脸坐标`);
                    detectedFaces = extractedFaces;
                    drawFaceBoxes();
                    return;
                }

                // 如果仍然没有找到，且在专注人脸识别模式下，尝试查找任何四个连续的数字作为可能的坐标
                // 这是最后的尝试，只在专注模式下进行，以减少误判
                if (faceDetectionMode.checked) {
                    const numberGroups = response.match(/\d+\s*,\s*\d+\s*,\s*\d+\s*,\s*\d+/g);
                    if (numberGroups) {
                        extractedFaces = [];
                        numberGroups.forEach(group => {
                            const numbers = group.split(',').map(n => parseInt(n.trim()));
                            if (numbers.length === 4) {
                                extractedFaces.push({
                                    x: numbers[0],
                                    y: numbers[1],
                                    width: numbers[2],
                                    height: numbers[3]
                                });
                            }
                        });

                        if (extractedFaces.length > 0) {
                            console.log(`从数字组中提取到${extractedFaces.length}个可能的人脸坐标`);
                            detectedFaces = extractedFaces;
                        }
                    }
                }

                // 绘制找到的人脸框
                drawFaceBoxes();

            } catch (e) {
                console.error('解析人脸检测响应失败:', e);
                // 确保清除人脸框
                detectedFaces = [];
                drawFaceBoxes();
            }
        }

        // 返回响应文本（字符串）
        async function sendChatCompletionRequest(instruction, imageBase64URL) {
            const response = await fetch(`${baseURL.value}/v1/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    max_tokens: 500,
                    messages: [
                        { role: 'user', content: [
                            { type: 'text', text: instruction },
                            { type: 'image_url', image_url: {
                                url: imageBase64URL,
                            } }
                        ] },
                    ]
                })
            });
            if (!response.ok) {
                const errorData = await response.text();
                return `服务器错误: ${response.status} - ${errorData}`;
            }
            const data = await response.json();
            return data.choices[0].message.content;
        }

        // 1. 页面加载时请求摄像头权限
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                video.srcObject = stream;
                responseText.value = "已获取摄像头访问权限。准备开始。";
            } catch (err) {
                console.error("访问摄像头出错:", err);
                responseText.value = `访问摄像头出错: ${err.name} - ${err.message}。请确保已授予权限并且您正在使用HTTPS或localhost。`;
                alert(`访问摄像头出错: ${err.name}。请确保您已授予权限并且正在使用HTTPS或localhost。`);
            }
        }

        function captureImage() {
            if (currentMode === 'camera') {
                if (!stream || !video.videoWidth) {
                    console.warn("视频流未准备好进行捕获。");
                    return null;
                }
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const context = canvas.getContext('2d');
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                return canvas.toDataURL('image/jpeg', 0.8); // 使用JPEG以获得更小的尺寸，0.8质量
            } else if (currentMode === 'image') {
                if (selectedImage.src && !selectedImage.classList.contains('hidden')) {
                    canvas.width = selectedImage.naturalWidth;
                    canvas.height = selectedImage.naturalHeight;
                    const context = canvas.getContext('2d');
                    context.drawImage(selectedImage, 0, 0, canvas.width, canvas.height);
                    return canvas.toDataURL('image/jpeg', 0.8);
                } else {
                    return null;
                }
            }
            return null;
        }

        // 处理本地图像上传
        function handleImageUpload(event) {
            const file = event.target.files[0];
            if (file && file.type.match('image.*')) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    selectedImage.src = e.target.result;
                    selectedImage.classList.remove('hidden');
                };
                reader.readAsDataURL(file);
            }
        }

        // 处理URL图像加载
        function handleUrlImage() {
            const url = imageUrl.value.trim();
            if (url) {
                // 使用代理或CORS友好的方式加载图像
                selectedImage.src = url;
                selectedImage.classList.remove('hidden');
                selectedImage.onerror = function() {
                    responseText.value = "无法加载图像URL。请检查URL是否正确或尝试其他图像。";
                    selectedImage.classList.add('hidden');
                };
            }
        }

        async function sendData() {
            if (!isProcessing) return; // 确保如果处理时间超过间隔时间，不会有重叠的请求

            // 根据是否勾选人脸检测模式来决定使用哪个指令
            let instruction = instructionText.value;

            // 确保在人脸检测模式下始终使用人脸检测指令
            if (faceDetectionMode.checked && instruction !== faceDetectionInstruction) {
                instruction = faceDetectionInstruction;
                instructionText.value = faceDetectionInstruction;
            }

            const imageBase64URL = captureImage();

            if (!imageBase64URL) {
                if (currentMode === 'camera') {
                    responseText.value = "捕获图像失败。视频流可能未激活。";
                } else {
                    responseText.value = "未选择图像或图像加载失败。";
                }
                return;
            }

            const payload = {
                instruction: instruction,
                imageBase64URL: imageBase64URL
            };

            try {
                const response = await sendChatCompletionRequest(payload.instruction, payload.imageBase64URL);
                responseText.value = response;

                // 解析响应中的人脸检测结果并绘制红色框
                if (currentMode === 'camera') {
                    // 在人脸检测模式下强制解析人脸坐标
                    if (faceDetectionMode.checked) {
                        parseFaceDetectionResponse(response);
                    } else {
                        // 在普通模式下，只有当指令包含人脸检测相关内容时才解析
                        if (instruction.toLowerCase().includes('face') ||
                            instruction.toLowerCase().includes('detect') ||
                            instruction.toLowerCase().includes('bounding box')) {
                            parseFaceDetectionResponse(response);
                        } else {
                            // 清除之前的人脸框和相关状态
                            detectedFaces = [];
                            previousFaces = [];
                            noFaceCounter = 0;
                            drawFaceBoxes();
                        }
                    }
                }
            } catch (error) {
                console.error('发送数据出错:', error);
                responseText.value = `错误: ${error.message}`;
                // 清除人脸框和相关状态
                detectedFaces = [];
                previousFaces = [];
                noFaceCounter = 0;
                drawFaceBoxes();
            }
        }

        function handleStart() {
            if (currentMode === 'camera' && !stream) {
                responseText.value = "摄像头不可用。无法开始。";
                alert("摄像头不可用。请先授予权限或切换到图像模式。");
                return;
            }

            if (currentMode === 'image' && (!selectedImage.src || selectedImage.classList.contains('hidden'))) {
                responseText.value = "未选择图像。请先上传图像或提供图像URL。";
                alert("请先选择一张图像。");
                return;
            }

            isProcessing = true;
            startButton.textContent = "停止";
            startButton.classList.remove('start');
            startButton.classList.add('stop');

            instructionText.disabled = true;
            intervalSelect.disabled = true;
            cameraModeBtn.disabled = true;
            imageModeBtn.disabled = true;
            faceDetectionMode.disabled = true;

            if (currentMode === 'image') {
                imageUpload.disabled = true;
                imageUrl.disabled = true;
                loadUrlImageBtn.disabled = true;
            }

            responseText.value = "处理已开始...";

            const intervalMs = parseInt(intervalSelect.value, 10);

            // 初始立即调用
            sendData();

            // 然后设置间隔
            intervalId = setInterval(sendData, intervalMs);
        }

        function handleStop() {
            isProcessing = false;
            if (intervalId) {
                clearInterval(intervalId);
                intervalId = null;
            }
            startButton.textContent = "开始";
            startButton.classList.remove('stop');
            startButton.classList.add('start');

            instructionText.disabled = false;
            intervalSelect.disabled = false;
            cameraModeBtn.disabled = false;
            imageModeBtn.disabled = false;
            faceDetectionMode.disabled = false;

            if (currentMode === 'image') {
                imageUpload.disabled = false;
                imageUrl.disabled = false;
                loadUrlImageBtn.disabled = false;
            }

            if (responseText.value.startsWith("处理已开始...")) {
                responseText.value = "处理已停止。";
            }
        }

        startButton.addEventListener('click', () => {
            if (isProcessing) {
                handleStop();
            } else {
                handleStart();
            }
        });

        // 模式切换处理
        function switchToCamera() {
            currentMode = 'camera';
            cameraModeBtn.classList.add('active');
            imageModeBtn.classList.remove('active');
            cameraContainer.classList.remove('hidden');
            imageContainer.classList.add('hidden');

            // 清除人脸检测框和相关状态
            detectedFaces = [];
            previousFaces = [];
            noFaceCounter = 0;
            drawFaceBoxes();

            // 如果摄像头未初始化，尝试初始化
            if (!stream) {
                initCamera();
            }
        }

        function switchToImage() {
            currentMode = 'image';
            cameraModeBtn.classList.remove('active');
            imageModeBtn.classList.add('active');
            cameraContainer.classList.add('hidden');
            imageContainer.classList.remove('hidden');

            // 清除人脸检测框和相关状态
            detectedFaces = [];
            previousFaces = [];
            noFaceCounter = 0;
            drawFaceBoxes();
        }

        // 添加模式切换事件监听器
        cameraModeBtn.addEventListener('click', switchToCamera);
        imageModeBtn.addEventListener('click', switchToImage);

        // 添加图像上传和URL加载事件监听器
        imageUpload.addEventListener('change', handleImageUpload);
        loadUrlImageBtn.addEventListener('click', handleUrlImage);

        // 图像URL输入框回车键处理
        imageUrl.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                handleUrlImage();
            }
        });

        // 人脸检测模式复选框事件监听器
        faceDetectionMode.addEventListener('change', function() {
            if (this.checked) {
                // 保存当前用户输入的指令（如果不是默认指令）
                if (instructionText.value !== defaultInstruction &&
                    instructionText.value !== faceDetectionInstruction) {
                    instructionText.dataset.userInstruction = instructionText.value;
                }
                // 切换到人脸检测指令
                instructionText.value = faceDetectionInstruction;
                // 如果在摄像头模式下，清除之前的人脸框
                if (currentMode === 'camera') {
                    detectedFaces = [];
                    previousFaces = [];
                    noFaceCounter = 0;
                    drawFaceBoxes();
                }
            } else {
                // 恢复到用户之前的指令或默认指令
                instructionText.value = instructionText.dataset.userInstruction || defaultInstruction;
                // 清除人脸框
                detectedFaces = [];
                previousFaces = [];
                noFaceCounter = 0;
                drawFaceBoxes();
            }
        });

        // 页面加载时初始化摄像头
        window.addEventListener('DOMContentLoaded', initCamera);

        // 可选：当页面关闭/导航离开时停止流以释放摄像头
        window.addEventListener('beforeunload', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            if (intervalId) {
                clearInterval(intervalId);
            }
        });

    </script>
</body>
</html>